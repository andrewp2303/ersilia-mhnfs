{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "56e4b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pickle import dump\n",
    "import pickle as pkl\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import copy\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "FS_MOL_CHECKOUT_PATH = os.path.join('/Users/andrew/Code/ersilia/ersilia-fsmol/') # TODO set path to FS-Mol repo\n",
    "FS_MOL_DATASET_PATH = os.path.join('/Users/andrew/Code/ersilia/bioassays/dataset/min_size_16') # TODO set path to FS-Mol repo\n",
    "\n",
    "os.chdir(FS_MOL_CHECKOUT_PATH)\n",
    "sys.path.insert(0, FS_MOL_CHECKOUT_PATH)\n",
    "\n",
    "from fs_mol.data import FSMolDataset, DataFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14280c0a",
   "metadata": {},
   "source": [
    "# Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b275506",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FSMolDataset.from_directory(FS_MOL_DATASET_PATH)\n",
    "\n",
    "task_iterable_train = dataset.get_task_reading_iterable(DataFold.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42610e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task names\n",
    "tasks_train = list()\n",
    "\n",
    "for task in iter(task_iterable_train):\n",
    "    tasks_train.append(task.name)\n",
    "    \n",
    "# Task names to id dict\n",
    "tasks_train_id_dict = {}\n",
    "for i in range(len(tasks_train)):\n",
    "    tasks_train_id_dict[tasks_train[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b2573afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mol_id by comparing canonical smiles\n",
    "# Make triplett: Mol_id, Task_id, Labels\n",
    "\n",
    "mol_ids = list()\n",
    "task_ids = list()\n",
    "labels = list()\n",
    "\n",
    "train_smiles_molId_dict = dict()\n",
    "id_counter = 0\n",
    "\n",
    "fingerprints = dict()\n",
    "descriptors = dict()\n",
    "\n",
    "for task in iter(task_iterable_train):\n",
    "    for mol_idx in range(len(task.samples)):\n",
    "        \n",
    "        if task.samples[mol_idx].smiles not in list(train_smiles_molId_dict.keys()):\n",
    "            train_smiles_molId_dict[task.samples[mol_idx].smiles] = id_counter\n",
    "            id_counter += 1\n",
    "            \n",
    "        mol_ids.append(train_smiles_molId_dict[task.samples[mol_idx].smiles])\n",
    "        task_ids.append(tasks_train_id_dict[task.name])\n",
    "        labels.append(task.samples[mol_idx].bool_label)\n",
    "        \n",
    "        if task.samples[mol_idx].smiles not in list(fingerprints.keys()):\n",
    "            fingerprints[task.samples[mol_idx].smiles] = task.samples[mol_idx].fingerprint\n",
    "            descriptors[task.samples[mol_idx].smiles] = task.samples[mol_idx].descriptors\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "af9c47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make numpy arrays for fingerprints and descriptors\n",
    "\n",
    "fingerprints_temp = dict()\n",
    "for key,value in zip(fingerprints.keys(),fingerprints.values()):\n",
    "    fingerprints_temp[train_smiles_molId_dict[key]] = value\n",
    "\n",
    "descriptors_temp = dict()\n",
    "for key,value in zip(descriptors.keys(),descriptors.values()):\n",
    "    descriptors_temp[train_smiles_molId_dict[key]] = value\n",
    "\n",
    "fingerprints = np.array(list(fingerprints_temp.values()))\n",
    "descriptors = np.array(list(descriptors_temp.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "89edfec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute quantils for descriptors\n",
    "descriptors_raw_forECDF = copy.deepcopy(descriptors)\n",
    "#TODO change path\n",
    "# make a directory if it doesn't exist\n",
    "if not os.path.exists('/Users/andrew/Code/ersilia/ersilia-mhnfs/data/preprocessed_datasets/training'):\n",
    "    os.makedirs('/Users/andrew/Code/ersilia/ersilia-mhnfs/data/preprocessed_datasets/training')\n",
    "np.save('/Users/andrew/Code/ersilia/ersilia-mhnfs/data/preprocessed_datasets/training/descriptors_raw_forECDF.npy',\n",
    "        descriptors_raw_forECDF)\n",
    "\n",
    "descriptors_quantils = np.zeros_like(descriptors_raw_forECDF)\n",
    "\n",
    "for column in range(descriptors_raw_forECDF.shape[1]):\n",
    "    raw_values = descriptors_raw_forECDF[:,column].reshape(-1)\n",
    "    ecdf = ECDF(raw_values)\n",
    "    quantils = ecdf(raw_values)\n",
    "    \n",
    "    descriptors_quantils[:, column] = quantils\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dcac5721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16214, 2258)\n",
      "(16214, 2248)\n"
     ]
    }
   ],
   "source": [
    "# Make numpy array: mol_inputs\n",
    "mol_inputs = np.hstack([fingerprints, descriptors_quantils])\n",
    "\n",
    "print(mol_inputs.shape)\n",
    "mol_inputs[0:5,:]\n",
    "\n",
    "# TODO: for now, we are cutting off the last 10 columns\n",
    "mol_inputs = mol_inputs[:, :-10]\n",
    "print(mol_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "344ddb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize mol_inputs and save scaler\n",
    "mol_inputs[mol_inputs.astype('str') == 'nan'] = 0\n",
    "mol_inputs[mol_inputs.astype('str') == 'inf'] = 0\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(mol_inputs)\n",
    "#TODO change path\n",
    "dump(scaler, open('/Users/andrew/Code/ersilia/ersilia-mhnfs/data/preprocessed_datasets/scaler_trainFitted.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "670aa440",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_inputs = scaler.transform(mol_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "66b38045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active dict\n",
    "triplett_ds = pd.DataFrame({'mol':mol_ids,\n",
    "                            'task':task_ids,\n",
    "                            'labels':labels})\n",
    "\n",
    "task_actives = dict()\n",
    "task_inactives = dict()\n",
    "\n",
    "for task in np.unique(task_ids):\n",
    "    subset_task = triplett_ds[triplett_ds['task'] == task]\n",
    "    subset_actives = subset_task[subset_task['labels'] == True]\n",
    "    subset_inactives = subset_task[subset_task['labels'] == False]\n",
    "    \n",
    "    set_actives = list(subset_actives['mol'])\n",
    "    set_inactives = list(subset_inactives['mol'])\n",
    "    if len(set_actives) == 0:\n",
    "        print(\"empty list of actives!\")\n",
    "        continue\n",
    "        # raise ValueError('Active set: Empty list!')\n",
    "    if len(set_inactives) == 0:\n",
    "        print(\"empty list of inactives!\")\n",
    "        continue\n",
    "        # raise ValueError('Inactive set: Empty list!')\n",
    "    \n",
    "    # TODO: figure out why some tasks have no actives / inactives\n",
    "    task_actives[task] = set_actives\n",
    "    task_inactives[task] = set_inactives\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "167e94d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save files\n",
    "# molecular features\n",
    "#TODO change path\n",
    "path_preproc = '/Users/andrew/Code/ersilia/ersilia-mhnfs/data/preprocessed_datasets'\n",
    "np.save(f'{path_preproc}/training/mol_inputs.npy', mol_inputs)\n",
    "\n",
    "# Tripletts\n",
    "mol_ids = np.array(mol_ids).reshape(-1,1)\n",
    "task_ids = np.array(task_ids).reshape(-1,1)\n",
    "labels = np.array(labels).reshape(-1,1)\n",
    "#TODO change path\n",
    "np.save(f'{path_preproc}/training/mol_ids.npy', mol_ids)\n",
    "#TODO change path\n",
    "np.save(f'{path_preproc}/training/task_ids.npy', task_ids)\n",
    "#TODO change path\n",
    "np.save(f'{path_preproc}/training/labels.npy', labels)\n",
    "\n",
    "# Dicts\n",
    "#TODO change path\n",
    "dump(tasks_train_id_dict, open(f'{path_preproc}/training/'\n",
    "                               'dict_task_names_id.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(train_smiles_molId_dict, open(f'{path_preproc}/training/'\n",
    "                               'dict_mol_smiles_id.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(task_actives, open(f'{path_preproc}/training/'\n",
    "                               'dict_task_id_activeMolecules.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(task_inactives, open(f'{path_preproc}/training/'\n",
    "                               'dict_task_id_inactiveMolecules.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b939e0bb",
   "metadata": {},
   "source": [
    "# Val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ed2422df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FSMolDataset.from_directory(FS_MOL_DATASET_PATH)\n",
    "task_iterable = dataset.get_task_reading_iterable(DataFold.VALIDATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4c1f494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task names\n",
    "tasks = list()\n",
    "\n",
    "for task in iter(task_iterable):\n",
    "    tasks.append(task.name)\n",
    "    \n",
    "# Task names to id dict\n",
    "tasks_id_dict = {}\n",
    "for i in range(len(tasks)):\n",
    "    tasks_id_dict[tasks[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "276615cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mol_id by comparing canonical smiles\n",
    "# Make triplett: Mol_id, Task_id, Labels\n",
    "\n",
    "mol_ids = list()\n",
    "task_ids = list()\n",
    "labels = list()\n",
    "\n",
    "smiles_molId_dict = dict()\n",
    "id_counter = 0\n",
    "\n",
    "fingerprints = dict()\n",
    "descriptors = dict()\n",
    "\n",
    "for task in iter(task_iterable):\n",
    "    for mol_idx in range(len(task.samples)):\n",
    "        \n",
    "        if task.samples[mol_idx].smiles not in list(smiles_molId_dict.keys()):\n",
    "            smiles_molId_dict[task.samples[mol_idx].smiles] = id_counter\n",
    "            id_counter += 1\n",
    "            \n",
    "        mol_ids.append(smiles_molId_dict[task.samples[mol_idx].smiles])\n",
    "        task_ids.append(tasks_id_dict[task.name])\n",
    "        labels.append(task.samples[mol_idx].bool_label)\n",
    "        \n",
    "        if task.samples[mol_idx].smiles not in list(fingerprints.keys()):\n",
    "            fingerprints[task.samples[mol_idx].smiles] = task.samples[mol_idx].fingerprint\n",
    "            descriptors[task.samples[mol_idx].smiles] = task.samples[mol_idx].descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6b338e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(837, 2258)\n",
      "(837, 2248)\n"
     ]
    }
   ],
   "source": [
    "# Make numpy array: mol_inputs\n",
    "\n",
    "fingerprints_temp = dict()\n",
    "for key,value in zip(fingerprints.keys(),fingerprints.values()):\n",
    "    fingerprints_temp[smiles_molId_dict[key]] = value\n",
    "\n",
    "descriptors_temp = dict()\n",
    "for key,value in zip(descriptors.keys(),descriptors.values()):\n",
    "    descriptors_temp[smiles_molId_dict[key]] = value\n",
    "\n",
    "fingerprints = np.array(list(fingerprints_temp.values()))\n",
    "descriptors = np.array(list(descriptors_temp.values()))\n",
    "\n",
    "# Compute quantils for descriptors\n",
    "descriptors_raw_forECDF = copy.deepcopy(descriptors)\n",
    "#TODO change path\n",
    "# make a directory if it doesn't exist\n",
    "if not os.path.exists(f'{path_preproc}/validation'):\n",
    "    os.makedirs(f'{path_preproc}/validation')\n",
    "np.save(f'{path_preproc}/validation/descriptors_raw_forECDF.npy',\n",
    "        descriptors_raw_forECDF)\n",
    "\n",
    "descriptors_quantils = np.zeros_like(descriptors_raw_forECDF)\n",
    "\n",
    "for column in range(descriptors_raw_forECDF.shape[1]):\n",
    "    raw_values = descriptors_raw_forECDF[:,column].reshape(-1)\n",
    "    ecdf = ECDF(raw_values)\n",
    "    quantils = ecdf(raw_values)\n",
    "    \n",
    "    descriptors_quantils[:, column] = quantils\n",
    "\n",
    "mol_inputs = np.hstack([fingerprints, descriptors_quantils])\n",
    "\n",
    "print(mol_inputs.shape)\n",
    "mol_inputs[0:5,:]\n",
    "\n",
    "# TODO: for now, we are cutting off the last 10 columns\n",
    "mol_inputs = mol_inputs[:, :-10]\n",
    "print(mol_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "df7df4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize mol_inputs\n",
    "mol_inputs[mol_inputs.astype('str') == 'nan'] = 0\n",
    "mol_inputs[mol_inputs.astype('str') == 'inf'] = 0\n",
    "\n",
    "#TODO change path\n",
    "scaler = pkl.load(open(f'{path_preproc}/scaler_trainFitted.pkl',\n",
    "                       'rb'))\n",
    "\n",
    "mol_inputs = scaler.transform(mol_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0047761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active dict\n",
    "triplett_ds = pd.DataFrame({'mol':mol_ids,\n",
    "                            'task':task_ids,\n",
    "                            'labels':labels})\n",
    "\n",
    "task_actives = dict()\n",
    "task_inactives = dict()\n",
    "\n",
    "for task in np.unique(task_ids):\n",
    "    subset_task = triplett_ds[triplett_ds['task'] == task]\n",
    "    subset_actives = subset_task[subset_task['labels'] == True]\n",
    "    subset_inactives = subset_task[subset_task['labels'] == False]\n",
    "    \n",
    "    set_actives = list(subset_actives['mol'])\n",
    "    set_inactives = list(subset_inactives['mol'])\n",
    "    if len(set_actives) == 0:\n",
    "        raise ValueError('Active set: Empty list!')\n",
    "    if len(set_inactives) == 0:\n",
    "        raise ValueError('Inactive set: Empty list!')\n",
    "    \n",
    "    task_actives[task] = set_actives\n",
    "    task_inactives[task] = set_inactives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "efe809fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save files\n",
    "# molecular features\n",
    "#TODO change path\n",
    "np.save(f'{path_preproc}/validation/mol_inputs.npy', mol_inputs)\n",
    "\n",
    "# Tripletts\n",
    "mol_ids = np.array(mol_ids).reshape(-1,1)\n",
    "task_ids = np.array(task_ids).reshape(-1,1)\n",
    "labels = np.array(labels).reshape(-1,1)\n",
    "#TODO change path\n",
    "np.save(f'{path_preproc}/validation/mol_ids.npy', mol_ids)\n",
    "#TODO change path\n",
    "np.save(f'{path_preproc}/validation/task_ids.npy', task_ids)\n",
    "#TODO change path\n",
    "np.save(f'{path_preproc}/validation/labels.npy', labels)\n",
    "\n",
    "# Dicts\n",
    "#TODO change path\n",
    "dump(tasks_id_dict, open(f'{path_preproc}/validation/'\n",
    "                               'dict_task_names_id.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(smiles_molId_dict, open(f'{path_preproc}/validation/'\n",
    "                               'dict_mol_smiles_id.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(task_actives, open(f'{path_preproc}/validation/'\n",
    "                               'dict_task_id_activeMolecules.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(task_inactives, open(f'{path_preproc}/validation/'\n",
    "                               'dict_task_id_inactiveMolecules.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6355eb",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8a5f9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FSMolDataset.from_directory(FS_MOL_DATASET_PATH)\n",
    "task_iterable = dataset.get_task_reading_iterable(DataFold.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cc354c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task names\n",
    "tasks = list()\n",
    "\n",
    "for task in iter(task_iterable):\n",
    "    tasks.append(task.name)\n",
    "    \n",
    "# Task names to id dict\n",
    "tasks_id_dict = {}\n",
    "for i in range(len(tasks)):\n",
    "    tasks_id_dict[tasks[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8875e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mol_id by comparing canonical smiles\n",
    "# Make triplett: Mol_id, Task_id, Labels\n",
    "\n",
    "mol_ids = list()\n",
    "task_ids = list()\n",
    "labels = list()\n",
    "\n",
    "smiles_molId_dict = dict()\n",
    "id_counter = 0\n",
    "\n",
    "fingerprints = dict()\n",
    "descriptors = dict()\n",
    "\n",
    "for task in iter(task_iterable):\n",
    "    for mol_idx in range(len(task.samples)):\n",
    "        \n",
    "        if task.samples[mol_idx].smiles not in list(smiles_molId_dict.keys()):\n",
    "            smiles_molId_dict[task.samples[mol_idx].smiles] = id_counter\n",
    "            id_counter += 1\n",
    "            \n",
    "        mol_ids.append(smiles_molId_dict[task.samples[mol_idx].smiles])\n",
    "        task_ids.append(tasks_id_dict[task.name])\n",
    "        labels.append(task.samples[mol_idx].bool_label)\n",
    "        \n",
    "        if task.samples[mol_idx].smiles not in list(fingerprints.keys()):\n",
    "            fingerprints[task.samples[mol_idx].smiles] = task.samples[mol_idx].fingerprint\n",
    "            descriptors[task.samples[mol_idx].smiles] = task.samples[mol_idx].descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2092accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4494, 2258)\n",
      "(4494, 2248)\n"
     ]
    }
   ],
   "source": [
    "# Make numpy array: mol_inputs\n",
    "\n",
    "fingerprints_temp = dict()\n",
    "for key,value in zip(fingerprints.keys(),fingerprints.values()):\n",
    "    fingerprints_temp[smiles_molId_dict[key]] = value\n",
    "\n",
    "descriptors_temp = dict()\n",
    "for key,value in zip(descriptors.keys(),descriptors.values()):\n",
    "    descriptors_temp[smiles_molId_dict[key]] = value\n",
    "\n",
    "fingerprints = np.array(list(fingerprints_temp.values()))\n",
    "descriptors = np.array(list(descriptors_temp.values()))\n",
    "\n",
    "# Compute quantils for descriptors\n",
    "descriptors_quantils = np.zeros_like(descriptors)\n",
    "\n",
    "for column in range(descriptors_raw_forECDF.shape[1]):\n",
    "    raw_values_ecdf = descriptors_raw_forECDF[:,column].reshape(-1)\n",
    "    raw_values = descriptors[:,column].reshape(-1)\n",
    "    \n",
    "    ecdf = ECDF(raw_values_ecdf)\n",
    "    quantils = ecdf(raw_values)\n",
    "    \n",
    "    descriptors_quantils[:, column] = quantils\n",
    "\n",
    "mol_inputs = np.hstack([fingerprints, descriptors_quantils])\n",
    "\n",
    "print(mol_inputs.shape)\n",
    "mol_inputs[0:5,:]\n",
    "\n",
    "# TODO: for now, we are cutting off the last 10 columns\n",
    "mol_inputs = mol_inputs[:, :-10]\n",
    "print(mol_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "37c6119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize mol_inputs\n",
    "mol_inputs[mol_inputs.astype('str') == 'nan'] = 0\n",
    "mol_inputs[mol_inputs.astype('str') == 'inf'] = 0\n",
    "\n",
    "#TODO change path\n",
    "scaler = pkl.load(open(f'{path_preproc}/scaler_trainFitted.pkl', 'rb'))\n",
    "\n",
    "mol_inputs = scaler.transform(mol_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "34e0838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active dict\n",
    "triplett_ds = pd.DataFrame({'mol':mol_ids,\n",
    "                            'task':task_ids,\n",
    "                            'labels':labels})\n",
    "\n",
    "task_actives = dict()\n",
    "task_inactives = dict()\n",
    "\n",
    "for task in np.unique(task_ids):\n",
    "    subset_task = triplett_ds[triplett_ds['task'] == task]\n",
    "    subset_actives = subset_task[subset_task['labels'] == True]\n",
    "    subset_inactives = subset_task[subset_task['labels'] == False]\n",
    "    \n",
    "    set_actives = list(subset_actives['mol'])\n",
    "    set_inactives = list(subset_inactives['mol'])\n",
    "    if len(set_actives) == 0:\n",
    "        raise ValueError('Active set: Empty list!')\n",
    "    if len(set_inactives) == 0:\n",
    "        raise ValueError('Inactive set: Empty list!')\n",
    "    \n",
    "    task_actives[task] = set_actives\n",
    "    task_inactives[task] = set_inactives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a70d9a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save files\n",
    "# molecular features\n",
    "#TODO change path\n",
    "if not os.path.exists(f'{path_preproc}/test/'):\n",
    "    os.makedirs(f'{path_preproc}/test/')\n",
    "np.save(f'{path_preproc}/test/mol_inputs.npy', mol_inputs)\n",
    "\n",
    "# Tripletts\n",
    "mol_ids = np.array(mol_ids).reshape(-1,1)\n",
    "task_ids = np.array(task_ids).reshape(-1,1)\n",
    "labels = np.array(labels).reshape(-1,1)\n",
    "#TODO change path\n",
    "np.save(f'{path_preproc}/test/mol_ids.npy', mol_ids)\n",
    "#TODO change path\n",
    "np.save(f'{path_preproc}/test/task_ids.npy', task_ids)\n",
    "#TODO change path\n",
    "np.save(f'{path_preproc}/test/labels.npy', labels)\n",
    "\n",
    "# Dicts\n",
    "#TODO change path\n",
    "dump(tasks_id_dict, open(f'{path_preproc}/test/'\n",
    "                               'dict_task_names_id.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(smiles_molId_dict, open(f'{path_preproc}/test/'\n",
    "                               'dict_mol_smiles_id.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(task_actives, open(f'{path_preproc}/test/'\n",
    "                               'dict_task_id_activeMolecules.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(task_inactives, open(f'{path_preproc}/test/'\n",
    "                               'dict_task_id_inactiveMolecules.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
