{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e4b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pickle import dump\n",
    "import pickle as pkl\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import copy\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "FS_MOL_CHECKOUT_PATH = os.path.join('path_to_fsmol_repo/FS-Mol') # TODO set path to FS-Mol repo\n",
    "FS_MOL_DATASET_PATH = os.path.join('path_to_fsmol_repo/FS-Mol/datasets/') # TODO set path to FS-Mol repo\n",
    "\n",
    "os.chdir(FS_MOL_CHECKOUT_PATH)\n",
    "sys.path.insert(0, FS_MOL_CHECKOUT_PATH)\n",
    "\n",
    "from fs_mol.data import FSMolDataset, DataFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14280c0a",
   "metadata": {},
   "source": [
    "# Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b275506",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FSMolDataset.from_directory(FS_MOL_DATASET_PATH)\n",
    "\n",
    "task_iterable_train = dataset.get_task_reading_iterable(DataFold.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42610e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task names\n",
    "tasks_train = list()\n",
    "\n",
    "for task in iter(task_iterable_train):\n",
    "    tasks_train.append(task.name)\n",
    "    \n",
    "# Task names to id dict\n",
    "tasks_train_id_dict = {}\n",
    "for i in range(len(tasks_train)):\n",
    "    tasks_train_id_dict[tasks_train[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2573afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mol_id by comparing canonical smiles\n",
    "# Make triplett: Mol_id, Task_id, Labels\n",
    "\n",
    "mol_ids = list()\n",
    "task_ids = list()\n",
    "labels = list()\n",
    "\n",
    "train_smiles_molId_dict = dict()\n",
    "id_counter = 0\n",
    "\n",
    "fingerprints = dict()\n",
    "descriptors = dict()\n",
    "\n",
    "for task in iter(task_iterable_train):\n",
    "    for mol_idx in range(len(task.samples)):\n",
    "        \n",
    "        if task.samples[mol_idx].smiles not in list(train_smiles_molId_dict.keys()):\n",
    "            train_smiles_molId_dict[task.samples[mol_idx].smiles] = id_counter\n",
    "            id_counter += 1\n",
    "            \n",
    "        mol_ids.append(train_smiles_molId_dict[task.samples[mol_idx].smiles])\n",
    "        task_ids.append(tasks_train_id_dict[task.name])\n",
    "        labels.append(task.samples[mol_idx].bool_label)\n",
    "        \n",
    "        if task.samples[mol_idx].smiles not in list(fingerprints.keys()):\n",
    "            fingerprints[task.samples[mol_idx].smiles] = task.samples[mol_idx].fingerprint\n",
    "            descriptors[task.samples[mol_idx].smiles] = task.samples[mol_idx].descriptors\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af9c47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make numpy arrays for fingerprints and descriptors\n",
    "\n",
    "fingerprints_temp = dict()\n",
    "for key,value in zip(fingerprints.keys(),fingerprints.values()):\n",
    "    fingerprints_temp[train_smiles_molId_dict[key]] = value\n",
    "\n",
    "descriptors_temp = dict()\n",
    "for key,value in zip(descriptors.keys(),descriptors.values()):\n",
    "    descriptors_temp[train_smiles_molId_dict[key]] = value\n",
    "\n",
    "fingerprints = np.array(list(fingerprints_temp.values()))\n",
    "descriptors = np.array(list(descriptors_temp.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89edfec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute quantils for descriptors\n",
    "descriptors_raw_forECDF = copy.deepcopy(descriptors)\n",
    "#TODO change path\n",
    "np.save('path_to_preprocessed_data_dir/training/descriptors_raw_forECDF.npy',\n",
    "        descriptors_raw_forECDF)\n",
    "\n",
    "descriptors_quantils = np.zeros_like(descriptors_raw_forECDF)\n",
    "\n",
    "for column in range(descriptors_raw_forECDF.shape[1]):\n",
    "    raw_values = descriptors_raw_forECDF[:,column].reshape(-1)\n",
    "    ecdf = ECDF(raw_values)\n",
    "    quantils = ecdf(raw_values)\n",
    "    \n",
    "    descriptors_quantils[:, column] = quantils\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcac5721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216827, 2248)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 2.        , 0.        , ..., 0.9312678 , 0.90536237,\n",
       "        0.99901307],\n",
       "       [0.        , 0.        , 0.        , ..., 0.9312678 , 0.98425013,\n",
       "        0.99901307],\n",
       "       [0.        , 1.        , 0.        , ..., 0.9312678 , 0.9554345 ,\n",
       "        0.99901307],\n",
       "       [0.        , 0.        , 0.        , ..., 0.9312678 , 0.97377634,\n",
       "        0.99901307],\n",
       "       [0.        , 0.        , 0.        , ..., 0.9312678 , 0.97377634,\n",
       "        0.99901307]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make numpy array: mol_inputs\n",
    "mol_inputs = np.hstack([fingerprints, descriptors_quantils])\n",
    "\n",
    "print(mol_inputs.shape)\n",
    "mol_inputs[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "344ddb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize mol_inputs and save scaler\n",
    "mol_inputs[mol_inputs.astype('str') == 'nan'] = 0\n",
    "mol_inputs[mol_inputs.astype('str') == 'inf'] = 0\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(mol_inputs)\n",
    "#TODO change path\n",
    "dump(scaler, open('path_to_preprocessed_data_dir/scaler_trainFitted.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "670aa440",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_inputs = scaler.transform(mol_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66b38045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active dict\n",
    "triplett_ds = pd.DataFrame({'mol':mol_ids,\n",
    "                            'task':task_ids,\n",
    "                            'labels':labels})\n",
    "\n",
    "task_actives = dict()\n",
    "task_inactives = dict()\n",
    "\n",
    "for task in np.unique(task_ids):\n",
    "    subset_task = triplett_ds[triplett_ds['task'] == task]\n",
    "    subset_actives = subset_task[subset_task['labels'] == True]\n",
    "    subset_inactives = subset_task[subset_task['labels'] == False]\n",
    "    \n",
    "    set_actives = list(subset_actives['mol'])\n",
    "    set_inactives = list(subset_inactives['mol'])\n",
    "    if len(set_actives) == 0:\n",
    "        raise ValueError('Active set: Empty list!')\n",
    "    if len(set_inactives) == 0:\n",
    "        raise ValueError('Inactive set: Empty list!')\n",
    "    \n",
    "    task_actives[task] = set_actives\n",
    "    task_inactives[task] = set_inactives\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167e94d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save files\n",
    "# molecular features\n",
    "#TODO change path\n",
    "np.save('path_to_preprocessed_data_dir/training/mol_inputs.npy', mol_inputs)\n",
    "\n",
    "# Tripletts\n",
    "mol_ids = np.array(mol_ids).reshape(-1,1)\n",
    "task_ids = np.array(task_ids).reshape(-1,1)\n",
    "labels = np.array(labels).reshape(-1,1)\n",
    "#TODO change path\n",
    "np.save('path_to_preprocessed_data_dir/training/mol_ids.npy', mol_ids)\n",
    "#TODO change path\n",
    "np.save('path_to_preprocessed_data_dir/training/task_ids.npy', task_ids)\n",
    "#TODO change path\n",
    "np.save('path_to_preprocessed_data_dir/training/labels.npy', labels)\n",
    "\n",
    "# Dicts\n",
    "#TODO change path\n",
    "dump(tasks_train_id_dict, open('path_to_preprocessed_data_dir/training/'\n",
    "                               'dict_task_names_id.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(train_smiles_molId_dict, open('path_to_preprocessed_data_dir/training/'\n",
    "                               'dict_mol_smiles_id.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(task_actives, open('path_to_preprocessed_data_dir/training/'\n",
    "                               'dict_task_id_activeMolecules.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(task_inactives, open('path_to_preprocessed_data_dir/training/'\n",
    "                               'dict_task_id_inactiveMolecules.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b939e0bb",
   "metadata": {},
   "source": [
    "# Val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed2422df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FSMolDataset.from_directory(FS_MOL_DATASET_PATH)\n",
    "task_iterable = dataset.get_task_reading_iterable(DataFold.VALIDATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c1f494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task names\n",
    "tasks = list()\n",
    "\n",
    "for task in iter(task_iterable):\n",
    "    tasks.append(task.name)\n",
    "    \n",
    "# Task names to id dict\n",
    "tasks_id_dict = {}\n",
    "for i in range(len(tasks)):\n",
    "    tasks_id_dict[tasks[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "276615cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mol_id by comparing canonical smiles\n",
    "# Make triplett: Mol_id, Task_id, Labels\n",
    "\n",
    "mol_ids = list()\n",
    "task_ids = list()\n",
    "labels = list()\n",
    "\n",
    "smiles_molId_dict = dict()\n",
    "id_counter = 0\n",
    "\n",
    "fingerprints = dict()\n",
    "descriptors = dict()\n",
    "\n",
    "for task in iter(task_iterable):\n",
    "    for mol_idx in range(len(task.samples)):\n",
    "        \n",
    "        if task.samples[mol_idx].smiles not in list(smiles_molId_dict.keys()):\n",
    "            smiles_molId_dict[task.samples[mol_idx].smiles] = id_counter\n",
    "            id_counter += 1\n",
    "            \n",
    "        mol_ids.append(smiles_molId_dict[task.samples[mol_idx].smiles])\n",
    "        task_ids.append(tasks_id_dict[task.name])\n",
    "        labels.append(task.samples[mol_idx].bool_label)\n",
    "        \n",
    "        if task.samples[mol_idx].smiles not in list(fingerprints.keys()):\n",
    "            fingerprints[task.samples[mol_idx].smiles] = task.samples[mol_idx].fingerprint\n",
    "            descriptors[task.samples[mol_idx].smiles] = task.samples[mol_idx].descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b338e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14735, 2248)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        , 0.        , ..., 0.9312678 , 0.90536237,\n",
       "        0.9443289 ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.9312678 , 0.90536237,\n",
       "        0.9443289 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.9312678 , 0.90536237,\n",
       "        0.9443289 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.9312678 , 0.90536237,\n",
       "        0.9443289 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.9312678 , 0.90536237,\n",
       "        0.9443289 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make numpy array: mol_inputs\n",
    "\n",
    "fingerprints_temp = dict()\n",
    "for key,value in zip(fingerprints.keys(),fingerprints.values()):\n",
    "    fingerprints_temp[smiles_molId_dict[key]] = value\n",
    "\n",
    "descriptors_temp = dict()\n",
    "for key,value in zip(descriptors.keys(),descriptors.values()):\n",
    "    descriptors_temp[smiles_molId_dict[key]] = value\n",
    "\n",
    "fingerprints = np.array(list(fingerprints_temp.values()))\n",
    "descriptors = np.array(list(descriptors_temp.values()))\n",
    "\n",
    "# Compute quantils for descriptors\n",
    "descriptors_quantils = np.zeros_like(descriptors)\n",
    "\n",
    "for column in range(descriptors_raw_forECDF.shape[1]):\n",
    "    raw_values_ecdf = descriptors_raw_forECDF[:,column].reshape(-1)\n",
    "    raw_values = descriptors[:,column].reshape(-1)\n",
    "    \n",
    "    ecdf = ECDF(raw_values_ecdf)\n",
    "    quantils = ecdf(raw_values)\n",
    "    \n",
    "    descriptors_quantils[:, column] = quantils\n",
    "\n",
    "mol_inputs = np.hstack([fingerprints, descriptors_quantils])\n",
    "\n",
    "print(mol_inputs.shape)\n",
    "mol_inputs[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df7df4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize mol_inputs\n",
    "mol_inputs[mol_inputs.astype('str') == 'nan'] = 0\n",
    "mol_inputs[mol_inputs.astype('str') == 'inf'] = 0\n",
    "\n",
    "#TODO change path\n",
    "scaler = pkl.load(open('path_to_preprocessed_data_dir/scaler_trainFitted.pkl',\n",
    "                       'rb'))\n",
    "\n",
    "mol_inputs = scaler.transform(mol_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0047761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active dict\n",
    "triplett_ds = pd.DataFrame({'mol':mol_ids,\n",
    "                            'task':task_ids,\n",
    "                            'labels':labels})\n",
    "\n",
    "task_actives = dict()\n",
    "task_inactives = dict()\n",
    "\n",
    "for task in np.unique(task_ids):\n",
    "    subset_task = triplett_ds[triplett_ds['task'] == task]\n",
    "    subset_actives = subset_task[subset_task['labels'] == True]\n",
    "    subset_inactives = subset_task[subset_task['labels'] == False]\n",
    "    \n",
    "    set_actives = list(subset_actives['mol'])\n",
    "    set_inactives = list(subset_inactives['mol'])\n",
    "    if len(set_actives) == 0:\n",
    "        raise ValueError('Active set: Empty list!')\n",
    "    if len(set_inactives) == 0:\n",
    "        raise ValueError('Inactive set: Empty list!')\n",
    "    \n",
    "    task_actives[task] = set_actives\n",
    "    task_inactives[task] = set_inactives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efe809fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save files\n",
    "# molecular features\n",
    "#TODO change path\n",
    "np.save('path_to_preprocessed_data_dir/validation/mol_inputs.npy', mol_inputs)\n",
    "\n",
    "# Tripletts\n",
    "mol_ids = np.array(mol_ids).reshape(-1,1)\n",
    "task_ids = np.array(task_ids).reshape(-1,1)\n",
    "labels = np.array(labels).reshape(-1,1)\n",
    "#TODO change path\n",
    "np.save('path_to_preprocessed_data_dir/validation/mol_ids.npy', mol_ids)\n",
    "#TODO change path\n",
    "np.save('path_to_preprocessed_data_dir/validation/task_ids.npy', task_ids)\n",
    "#TODO change path\n",
    "np.save('path_to_preprocessed_data_dir/validation/labels.npy', labels)\n",
    "\n",
    "# Dicts\n",
    "#TODO change path\n",
    "dump(tasks_id_dict, open('path_to_preprocessed_data_dir/validation/'\n",
    "                               'dict_task_names_id.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(smiles_molId_dict, open('path_to_preprocessed_data_dir/validation/'\n",
    "                               'dict_mol_smiles_id.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(task_actives, open('path_to_preprocessed_data_dir/validation/'\n",
    "                               'dict_task_id_activeMolecules.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(task_inactives, open('path_to_preprocessed_data_dir/validation/'\n",
    "                               'dict_task_id_inactiveMolecules.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6355eb",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a5f9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FSMolDataset.from_directory(FS_MOL_DATASET_PATH)\n",
    "task_iterable = dataset.get_task_reading_iterable(DataFold.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc354c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task names\n",
    "tasks = list()\n",
    "\n",
    "for task in iter(task_iterable):\n",
    "    tasks.append(task.name)\n",
    "    \n",
    "# Task names to id dict\n",
    "tasks_id_dict = {}\n",
    "for i in range(len(tasks)):\n",
    "    tasks_id_dict[tasks[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8875e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mol_id by comparing canonical smiles\n",
    "# Make triplett: Mol_id, Task_id, Labels\n",
    "\n",
    "mol_ids = list()\n",
    "task_ids = list()\n",
    "labels = list()\n",
    "\n",
    "smiles_molId_dict = dict()\n",
    "id_counter = 0\n",
    "\n",
    "fingerprints = dict()\n",
    "descriptors = dict()\n",
    "\n",
    "for task in iter(task_iterable):\n",
    "    for mol_idx in range(len(task.samples)):\n",
    "        \n",
    "        if task.samples[mol_idx].smiles not in list(smiles_molId_dict.keys()):\n",
    "            smiles_molId_dict[task.samples[mol_idx].smiles] = id_counter\n",
    "            id_counter += 1\n",
    "            \n",
    "        mol_ids.append(smiles_molId_dict[task.samples[mol_idx].smiles])\n",
    "        task_ids.append(tasks_id_dict[task.name])\n",
    "        labels.append(task.samples[mol_idx].bool_label)\n",
    "        \n",
    "        if task.samples[mol_idx].smiles not in list(fingerprints.keys()):\n",
    "            fingerprints[task.samples[mol_idx].smiles] = task.samples[mol_idx].fingerprint\n",
    "            descriptors[task.samples[mol_idx].smiles] = task.samples[mol_idx].descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2092accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27518, 2248)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.9312678 , 0.90536237,\n",
       "        0.9443289 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.9312678 , 0.97377634,\n",
       "        0.9443289 ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.9312678 , 0.90536237,\n",
       "        0.9443289 ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.9312678 , 0.90536237,\n",
       "        0.9443289 ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.9312678 , 0.90536237,\n",
       "        0.9443289 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make numpy array: mol_inputs\n",
    "\n",
    "fingerprints_temp = dict()\n",
    "for key,value in zip(fingerprints.keys(),fingerprints.values()):\n",
    "    fingerprints_temp[smiles_molId_dict[key]] = value\n",
    "\n",
    "descriptors_temp = dict()\n",
    "for key,value in zip(descriptors.keys(),descriptors.values()):\n",
    "    descriptors_temp[smiles_molId_dict[key]] = value\n",
    "\n",
    "fingerprints = np.array(list(fingerprints_temp.values()))\n",
    "descriptors = np.array(list(descriptors_temp.values()))\n",
    "\n",
    "# Compute quantils for descriptors\n",
    "descriptors_quantils = np.zeros_like(descriptors)\n",
    "\n",
    "for column in range(descriptors_raw_forECDF.shape[1]):\n",
    "    raw_values_ecdf = descriptors_raw_forECDF[:,column].reshape(-1)\n",
    "    raw_values = descriptors[:,column].reshape(-1)\n",
    "    \n",
    "    ecdf = ECDF(raw_values_ecdf)\n",
    "    quantils = ecdf(raw_values)\n",
    "    \n",
    "    descriptors_quantils[:, column] = quantils\n",
    "\n",
    "mol_inputs = np.hstack([fingerprints, descriptors_quantils])\n",
    "\n",
    "print(mol_inputs.shape)\n",
    "mol_inputs[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37c6119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize mol_inputs\n",
    "mol_inputs[mol_inputs.astype('str') == 'nan'] = 0\n",
    "mol_inputs[mol_inputs.astype('str') == 'inf'] = 0\n",
    "\n",
    "#TODO change path\n",
    "scaler = pkl.load(open('path_to_preprocessed_data_dir/scaler_trainFitted.pkl', 'rb'))\n",
    "\n",
    "mol_inputs = scaler.transform(mol_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34e0838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active dict\n",
    "triplett_ds = pd.DataFrame({'mol':mol_ids,\n",
    "                            'task':task_ids,\n",
    "                            'labels':labels})\n",
    "\n",
    "task_actives = dict()\n",
    "task_inactives = dict()\n",
    "\n",
    "for task in np.unique(task_ids):\n",
    "    subset_task = triplett_ds[triplett_ds['task'] == task]\n",
    "    subset_actives = subset_task[subset_task['labels'] == True]\n",
    "    subset_inactives = subset_task[subset_task['labels'] == False]\n",
    "    \n",
    "    set_actives = list(subset_actives['mol'])\n",
    "    set_inactives = list(subset_inactives['mol'])\n",
    "    if len(set_actives) == 0:\n",
    "        raise ValueError('Active set: Empty list!')\n",
    "    if len(set_inactives) == 0:\n",
    "        raise ValueError('Inactive set: Empty list!')\n",
    "    \n",
    "    task_actives[task] = set_actives\n",
    "    task_inactives[task] = set_inactives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a70d9a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save files\n",
    "# molecular features\n",
    "#TODO change path\n",
    "np.save('path_to_preprocessed_data_dir/test/mol_inputs.npy', mol_inputs)\n",
    "\n",
    "# Tripletts\n",
    "mol_ids = np.array(mol_ids).reshape(-1,1)\n",
    "task_ids = np.array(task_ids).reshape(-1,1)\n",
    "labels = np.array(labels).reshape(-1,1)\n",
    "#TODO change path\n",
    "np.save('path_to_preprocessed_data_dir/test/mol_ids.npy', mol_ids)\n",
    "#TODO change path\n",
    "np.save('path_to_preprocessed_data_dir/test/task_ids.npy', task_ids)\n",
    "#TODO change path\n",
    "np.save('path_to_preprocessed_data_dir/test/labels.npy', labels)\n",
    "\n",
    "# Dicts\n",
    "#TODO change path\n",
    "dump(tasks_id_dict, open('path_to_preprocessed_data_dir/test/'\n",
    "                               'dict_task_names_id.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(smiles_molId_dict, open('path_to_preprocessed_data_dirtest/'\n",
    "                               'dict_mol_smiles_id.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(task_actives, open('path_to_preprocessed_data_dirtest/'\n",
    "                               'dict_task_id_activeMolecules.pkl', 'wb'))\n",
    "#TODO change path\n",
    "dump(task_inactives, open('path_to_preprocessed_data_dir/test/'\n",
    "                               'dict_task_id_inactiveMolecules.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
